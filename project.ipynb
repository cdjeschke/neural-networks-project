{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from hopfield_network import HopfieldNetwork\n",
    "from lippmann_exemplars import LippmanExemplars\n",
    "from random_exemplars import RandomExemplars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now initialize the network using these exemplars, completing a few checks to confirm the structure of the weights matrix is consistent with our expectations:\n",
    "- Is the matrix the correct size?  It should be 120 x 120 as each exemplar is 12x10, flattened to a 120 element vector.\n",
    "- Is the diagonal 0?  That is, does $w_{ij} = 0$ when $i = j$?\n",
    "- Is it symmetric?  That is, does $w_{ij} = w_{ji}$ when $i \\neq j$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5 nodes:  Hebb capactiy: 1.5533373364,  Storkey capacity: 2.78687758647\n",
      "P is 0.65\n",
      "For 6 nodes:  Hebb capactiy: 1.67433187965,  Storkey capacity: 3.16954117782\n",
      "P is 0.78\n",
      "For 7 nodes:  Hebb capactiy: 1.79864419829,  Storkey capacity: 3.54831077952\n",
      "P is 0.91\n",
      "For 8 nodes:  Hebb capactiy: 1.92359338785,  Storkey capacity: 3.9228493602\n",
      "P is 1.04\n",
      "For 9 nodes:  Hebb capactiy: 2.04803825991,  Storkey capacity: 4.293290619\n",
      "P is 1.17\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 10):\n",
    "    hebbian = (1.0 * i) / (2 * math.log(i))\n",
    "    storkey = (1.0 * i) / math.sqrt(2 * math.log(i))\n",
    "    print \"For {0} nodes:  Hebb capactiy: {1},  Storkey capacity: {2}\".format(i, hebbian, storkey)\n",
    "    \n",
    "    p = i * .13\n",
    "    print \"P is {0}\".format(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Network of 5 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 1.5533373364, Storkey capacity 2.78687758647\n",
      "\n",
      "Testing Network of 5 nodes with 2 exemplars\n",
      "Hebbian error rate: 15.0%.  Storkey error rate: 15.0%\n",
      "Hebbian capacity 1.5533373364, Storkey capacity 2.78687758647\n",
      "\n",
      "Testing Network of 5 nodes with 3 exemplars\n",
      "Hebbian error rate: 38.3333333333%.  Storkey error rate: 31.6666666667%\n",
      "Hebbian capacity 1.5533373364, Storkey capacity 2.78687758647\n",
      "\n",
      "Testing Network of 5 nodes with 4 exemplars\n",
      "Hebbian error rate: 58.75%.  Storkey error rate: 40.0%\n",
      "Hebbian capacity 1.5533373364, Storkey capacity 2.78687758647\n",
      "\n",
      "Testing Network of 6 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 1.67433187965, Storkey capacity 3.16954117782\n",
      "\n",
      "Testing Network of 6 nodes with 2 exemplars\n",
      "Hebbian error rate: 12.5%.  Storkey error rate: 12.5%\n",
      "Hebbian capacity 1.67433187965, Storkey capacity 3.16954117782\n",
      "\n",
      "Testing Network of 6 nodes with 3 exemplars\n",
      "Hebbian error rate: 31.6666666667%.  Storkey error rate: 16.6666666667%\n",
      "Hebbian capacity 1.67433187965, Storkey capacity 3.16954117782\n",
      "\n",
      "Testing Network of 6 nodes with 4 exemplars\n",
      "Hebbian error rate: 48.75%.  Storkey error rate: 35.0%\n",
      "Hebbian capacity 1.67433187965, Storkey capacity 3.16954117782\n",
      "\n",
      "Testing Network of 6 nodes with 5 exemplars\n",
      "Hebbian error rate: 68.0%.  Storkey error rate: 54.0%\n",
      "Hebbian capacity 1.67433187965, Storkey capacity 3.16954117782\n",
      "\n",
      "Testing Network of 7 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 7 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 7 nodes with 3 exemplars\n",
      "Hebbian error rate: 35.0%.  Storkey error rate: 16.6666666667%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 7 nodes with 4 exemplars\n",
      "Hebbian error rate: 42.5%.  Storkey error rate: 18.75%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 7 nodes with 5 exemplars\n",
      "Hebbian error rate: 75.0%.  Storkey error rate: 44.0%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 7 nodes with 6 exemplars\n",
      "Hebbian error rate: 76.6666666667%.  Storkey error rate: 51.6666666667%\n",
      "Hebbian capacity 1.79864419829, Storkey capacity 3.54831077952\n",
      "\n",
      "Testing Network of 8 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 2 exemplars\n",
      "Hebbian error rate: 10.0%.  Storkey error rate: 10.0%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 3 exemplars\n",
      "Hebbian error rate: 10.0%.  Storkey error rate: 3.33333333333%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 4 exemplars\n",
      "Hebbian error rate: 33.75%.  Storkey error rate: 16.25%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 5 exemplars\n",
      "Hebbian error rate: 65.0%.  Storkey error rate: 31.0%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 6 exemplars\n",
      "Hebbian error rate: 75.0%.  Storkey error rate: 43.3333333333%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 8 nodes with 7 exemplars\n",
      "Hebbian error rate: 75.0%.  Storkey error rate: 55.7142857143%\n",
      "Hebbian capacity 1.92359338785, Storkey capacity 3.9228493602\n",
      "\n",
      "Testing Network of 9 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 2 exemplars\n",
      "Hebbian error rate: 7.5%.  Storkey error rate: 7.5%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 3 exemplars\n",
      "Hebbian error rate: 21.6666666667%.  Storkey error rate: 3.33333333333%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 4 exemplars\n",
      "Hebbian error rate: 36.25%.  Storkey error rate: 7.5%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 5 exemplars\n",
      "Hebbian error rate: 76.0%.  Storkey error rate: 24.0%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 6 exemplars\n",
      "Hebbian error rate: 69.1666666667%.  Storkey error rate: 37.5%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 7 exemplars\n",
      "Hebbian error rate: 77.8571428571%.  Storkey error rate: 50.0%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 9 nodes with 8 exemplars\n",
      "Hebbian error rate: 81.875%.  Storkey error rate: 56.25%\n",
      "Hebbian capacity 2.04803825991, Storkey capacity 4.293290619\n",
      "\n",
      "Testing Network of 10 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 3 exemplars\n",
      "Hebbian error rate: 3.33333333333%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 4 exemplars\n",
      "Hebbian error rate: 38.75%.  Storkey error rate: 6.25%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 5 exemplars\n",
      "Hebbian error rate: 43.0%.  Storkey error rate: 19.0%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 6 exemplars\n",
      "Hebbian error rate: 70.0%.  Storkey error rate: 35.8333333333%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 7 exemplars\n",
      "Hebbian error rate: 76.4285714286%.  Storkey error rate: 35.0%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 8 exemplars\n",
      "Hebbian error rate: 82.5%.  Storkey error rate: 45.625%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 10 nodes with 9 exemplars\n",
      "Hebbian error rate: 87.2222222222%.  Storkey error rate: 56.1111111111%\n",
      "Hebbian capacity 2.17147240952, Storkey capacity 4.65990601785\n",
      "\n",
      "Testing Network of 11 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 3 exemplars\n",
      "Hebbian error rate: 13.3333333333%.  Storkey error rate: 3.33333333333%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 4 exemplars\n",
      "Hebbian error rate: 37.5%.  Storkey error rate: 6.25%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 5 exemplars\n",
      "Hebbian error rate: 57.0%.  Storkey error rate: 19.0%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 6 exemplars\n",
      "Hebbian error rate: 56.6666666667%.  Storkey error rate: 25.0%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 7 exemplars\n",
      "Hebbian error rate: 76.4285714286%.  Storkey error rate: 37.8571428571%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 8 exemplars\n",
      "Hebbian error rate: 77.5%.  Storkey error rate: 48.75%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 9 exemplars\n",
      "Hebbian error rate: 87.2222222222%.  Storkey error rate: 56.1111111111%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 11 nodes with 10 exemplars\n",
      "Hebbian error rate: 87.5%.  Storkey error rate: 60.5%\n",
      "Hebbian capacity 2.29367815283, Storkey capacity 5.02299309985\n",
      "\n",
      "Testing Network of 12 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 3 exemplars\n",
      "Hebbian error rate: 5.0%.  Storkey error rate: 3.33333333333%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 4 exemplars\n",
      "Hebbian error rate: 30.0%.  Storkey error rate: 2.5%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 5 exemplars\n",
      "Hebbian error rate: 47.0%.  Storkey error rate: 9.0%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 6 exemplars\n",
      "Hebbian error rate: 52.5%.  Storkey error rate: 11.6666666667%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 7 exemplars\n",
      "Hebbian error rate: 84.2857142857%.  Storkey error rate: 32.1428571429%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 8 exemplars\n",
      "Hebbian error rate: 73.75%.  Storkey error rate: 32.5%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 9 exemplars\n",
      "Hebbian error rate: 85.0%.  Storkey error rate: 55.0%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 10 exemplars\n",
      "Hebbian error rate: 85.5%.  Storkey error rate: 57.0%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 12 nodes with 11 exemplars\n",
      "Hebbian error rate: 91.8181818182%.  Storkey error rate: 66.3636363636%\n",
      "Hebbian capacity 2.41457762629, Storkey capacity 5.38283675356\n",
      "\n",
      "Testing Network of 13 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 3 exemplars\n",
      "Hebbian error rate: 3.33333333333%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 4 exemplars\n",
      "Hebbian error rate: 28.75%.  Storkey error rate: 5.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 5 exemplars\n",
      "Hebbian error rate: 51.0%.  Storkey error rate: 12.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 6 exemplars\n",
      "Hebbian error rate: 68.3333333333%.  Storkey error rate: 15.0%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 7 exemplars\n",
      "Hebbian error rate: 75.7142857143%.  Storkey error rate: 29.2857142857%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 8 exemplars\n",
      "Hebbian error rate: 81.25%.  Storkey error rate: 36.875%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 9 exemplars\n",
      "Hebbian error rate: 80.5555555556%.  Storkey error rate: 40.5555555556%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 10 exemplars\n",
      "Hebbian error rate: 86.0%.  Storkey error rate: 49.5%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 11 exemplars\n",
      "Hebbian error rate: 92.2727272727%.  Storkey error rate: 61.3636363636%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 13 nodes with 12 exemplars\n",
      "Hebbian error rate: 92.0833333333%.  Storkey error rate: 64.1666666667%\n",
      "Hebbian capacity 2.53416309413, Storkey capacity 5.7396968756\n",
      "\n",
      "Testing Network of 14 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 3 exemplars\n",
      "Hebbian error rate: 1.66666666667%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 4 exemplars\n",
      "Hebbian error rate: 27.5%.  Storkey error rate: 2.5%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 5 exemplars\n",
      "Hebbian error rate: 33.0%.  Storkey error rate: 4.0%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 6 exemplars\n",
      "Hebbian error rate: 64.1666666667%.  Storkey error rate: 10.8333333333%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 7 exemplars\n",
      "Hebbian error rate: 67.8571428571%.  Storkey error rate: 25.7142857143%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 8 exemplars\n",
      "Hebbian error rate: 83.125%.  Storkey error rate: 26.875%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 9 exemplars\n",
      "Hebbian error rate: 86.6666666667%.  Storkey error rate: 43.8888888889%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 10 exemplars\n",
      "Hebbian error rate: 90.5%.  Storkey error rate: 47.5%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 11 exemplars\n",
      "Hebbian error rate: 88.6363636364%.  Storkey error rate: 55.9090909091%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 12 exemplars\n",
      "Hebbian error rate: 95.8333333333%.  Storkey error rate: 62.9166666667%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 14 nodes with 13 exemplars\n",
      "Hebbian error rate: 91.1538461538%.  Storkey error rate: 66.9230769231%\n",
      "Hebbian capacity 2.65246227183, Storkey capacity 6.09380601969\n",
      "\n",
      "Testing Network of 15 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 3 exemplars\n",
      "Hebbian error rate: 3.33333333333%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 4 exemplars\n",
      "Hebbian error rate: 15.0%.  Storkey error rate: 2.5%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 5 exemplars\n",
      "Hebbian error rate: 30.0%.  Storkey error rate: 3.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 6 exemplars\n",
      "Hebbian error rate: 58.3333333333%.  Storkey error rate: 9.16666666667%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 7 exemplars\n",
      "Hebbian error rate: 68.5714285714%.  Storkey error rate: 17.8571428571%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 8 exemplars\n",
      "Hebbian error rate: 79.375%.  Storkey error rate: 23.75%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 9 exemplars\n",
      "Hebbian error rate: 86.6666666667%.  Storkey error rate: 30.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 10 exemplars\n",
      "Hebbian error rate: 85.5%.  Storkey error rate: 50.0%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 11 exemplars\n",
      "Hebbian error rate: 88.1818181818%.  Storkey error rate: 51.3636363636%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 12 exemplars\n",
      "Hebbian error rate: 89.1666666667%.  Storkey error rate: 54.1666666667%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 13 exemplars\n",
      "Hebbian error rate: 93.0769230769%.  Storkey error rate: 63.0769230769%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 15 nodes with 14 exemplars\n",
      "Hebbian error rate: 94.6428571429%.  Storkey error rate: 73.2142857143%\n",
      "Hebbian capacity 2.76952029802, Storkey capacity 6.44537077834\n",
      "\n",
      "Testing Network of 16 nodes with 1 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 2 exemplars\n",
      "Hebbian error rate: 0.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 3 exemplars\n",
      "Hebbian error rate: 5.0%.  Storkey error rate: 0.0%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 4 exemplars\n",
      "Hebbian error rate: 21.25%.  Storkey error rate: 1.25%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 5 exemplars\n",
      "Hebbian error rate: 33.0%.  Storkey error rate: 2.0%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 6 exemplars\n",
      "Hebbian error rate: 51.6666666667%.  Storkey error rate: 7.5%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 7 exemplars\n",
      "Hebbian error rate: 57.8571428571%.  Storkey error rate: 14.2857142857%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 8 exemplars\n",
      "Hebbian error rate: 76.875%.  Storkey error rate: 14.375%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 9 exemplars\n",
      "Hebbian error rate: 76.1111111111%.  Storkey error rate: 28.3333333333%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 10 exemplars\n",
      "Hebbian error rate: 89.5%.  Storkey error rate: 32.0%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 11 exemplars\n",
      "Hebbian error rate: 90.4545454545%.  Storkey error rate: 49.5454545455%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 12 exemplars\n",
      "Hebbian error rate: 94.1666666667%.  Storkey error rate: 53.75%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 13 exemplars\n",
      "Hebbian error rate: 95.3846153846%.  Storkey error rate: 65.3846153846%\n",
      "Hebbian capacity 2.88539008178, Storkey capacity 6.7945744023\n",
      "\n",
      "Testing Network of 16 nodes with 14 exemplars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5d26faf62d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#storkey network trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mstorkey_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mstorkey_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHopfieldNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Storkey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mexemplar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexemplars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorkey_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjeschke/Desktop/Education/Neural Networks/Project/git/neural-networks-project/hopfield_network.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v_exemplars, learning_rule, debug)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__hebbian_learning_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_exemplars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rule\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Storkey\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__storkey_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_exemplars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Unrecognized rule\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjeschke/Desktop/Education/Neural Networks/Project/git/neural-networks-project/hopfield_network.pyc\u001b[0m in \u001b[0;36m__storkey_learning\u001b[0;34m(self, v_exemplars)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;31m# 3rd term = 1/n h^v_{i,j} E^v_{j}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_neurons\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__weight_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexemplar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_neurons\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                          \u001b[0mexemplar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cjeschke/Desktop/Education/Neural Networks/Project/git/neural-networks-project/hopfield_network.pyc\u001b[0m in \u001b[0;36mh\u001b[0;34m(i, j, w, e, n)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mh_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mh_ij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test up to 20 nodes\n",
    "for nodes in range(5, 20):\n",
    "    \n",
    "    for num in range(1, nodes):\n",
    "        print \"\\nTesting Network of {0} nodes with {1} exemplars\".format(nodes, num)\n",
    "        \n",
    "        # 20 trials\n",
    "        hebbian_error_rates = []\n",
    "        storkey_error_rates = []\n",
    "        hebbian_capacity = None\n",
    "        storkey_capacity = None\n",
    "        for _ in range(0, 20):\n",
    "            exemplars = RandomExemplars.get_exemplars(nodes, num, randomize=True)\n",
    "            \n",
    "            # Hebbian network trial\n",
    "            hebbian_errors = 0\n",
    "            hebbian_network = HopfieldNetwork(exemplars, learning_rule=\"Hebb\")\n",
    "            for exemplar in exemplars:\n",
    "                results = hebbian_network.asynchronous_recall(exemplar)\n",
    "                p = results[-1]\n",
    "                if p != exemplar:\n",
    "                    hebbian_errors += 1\n",
    "            \n",
    "            rate = (1.0 * hebbian_errors)/len(exemplars)\n",
    "            hebbian_error_rates.append(rate)\n",
    "            hebbian_capacity = hebbian_network.capacity\n",
    "            \n",
    "            #storkey network trial\n",
    "            storkey_errors = 0\n",
    "            storkey_network = HopfieldNetwork(exemplars, learning_rule=\"Storkey\")\n",
    "            for exemplar in exemplars:\n",
    "                results = storkey_network.asynchronous_recall(exemplar)\n",
    "                p = results[-1]\n",
    "                if p!= exemplar:\n",
    "                    storkey_errors += 1\n",
    "                    \n",
    "            rate = (1.0 * storkey_errors)/len(exemplars)\n",
    "            storkey_error_rates.append(rate)\n",
    "            storkey_capacity = storkey_network.capacity\n",
    "            \n",
    "        hebbian_error_rate = (1.0 * sum(hebbian_error_rates)) / len(hebbian_error_rates)\n",
    "        storkey_error_rate = (1.0 * sum(storkey_error_rates)) / len(storkey_error_rates)\n",
    "        print \"Hebbian error rate: {0}%.  Storkey error rate: {1}%\".format(\n",
    "            hebbian_error_rate * 100, storkey_error_rate * 100)\n",
    "        print \"Hebbian capacity {0}, Storkey capacity {1}\".format(hebbian_capacity, storkey_capacity)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writeup regarding Hopfield networks, Hebbian & Storkey learning rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1: Successful digit exemplar retrieval from Hopfield networks**\n",
    "\n",
    "The usefulness of trained Hopfield Network hinges largely on the ability of the network to recall one of the exemplars $p$ on which it was trained when supplied a noisy variant $p^{\\prime}$. This recollection of an exemplar happens by first imposing the noisy varient $p^{\\prime}$ on the network to obtain an initial output, then (re)imposing that output and each subsequent output iteratively on the network until output no longer changes, having converged to a fixed point in the system - the expected exemplar $p$.\n",
    "\n",
    "Imposing the noisy input patterns on the network to recall an exemplar can occur synchronously or asynchronously. The former requires that for a timestep $t$ in the iteration,  each neuron in the network is activated simultaneously using the output produced from iteration $t-1$, typically accomplished through a simple matrix multiplication operation: ###TODO: Add details\n",
    "//OLD content\n",
    "applying the formula $x_{k+1} = F_{h}(\\textbf{W}x_{k})$ iteratively through $k=[0, n]$, where:\n",
    "- $x_k = p^{\\prime}$ when $k = 0$\n",
    "- $n$ is chosen somewhat arbitrarily, but generally large enough to ensure $x_{k=n}$ represents the exemplar $p$ we aim to retrieve _OR_ the network is stuck in a cycle, thus incapable of retrieving the exemplar at all.\n",
    "- $F_{h}$ is the hard limiting function, defined as \n",
    "- $\\textbf{W}$ is the weights matrix of the Hopfield Network\n",
    "\n",
    "\n",
    "Unfortunately, the synchronous approach is not without limitations. It provides no strong gaurantee of converging to a single output and may instead cycle through multiple output patterns repeatedly. It would be preferable then to use a modality that does create convergence so that we can readily identify a _final_ output of the network from which we can evaluate if it successfully recovered the exemplar we expected.  Asynchronous updating has been proven to result in this converage (citation - Lippmann). It executes as follows:\n",
    "## TODO: Describe asynchronous execution\n",
    "\n",
    "\n",
    "With our methodology for recalling exemplars established lets move on to our experiment. Here we will evaluate the ability to recover exemplars from a Hopfield network trained under the Hebbian & Storkey learning rules. The exemplars we have chosen are from the Lippmann paper (citation) as they were created by hand with the intent to exemplify the a Hopfield Network's ability to recall exemplars.  The exemplars consist of 8 patterns covering the digits 0, 1, 2, 3, 4, 6 and 9, with an additional pattern being a simple block. By observation, you can see that some patterns have significant overlap - such as the rightmost strokes for 2, 3 & 4 - while other patterns are distinctly seperate - such as the block & 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exemplars = LippmanExemplars.get_exemplars()\n",
    "\n",
    "figure, axes = plt.subplots(1, len(exemplars), figsize=(30,30))\n",
    "for i in range(0, len(exemplars)):\n",
    "    axes[i].imshow(LippmanExemplars.to_matrix(exemplars[i]), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our exemplars chosen, our experiment will look at what happens when we train a Hopfield Network under the Hebbian Learning rule, then attempt to recall each exemplar when imposing on the network a noisy varient.  We'll continue to replicate Lippmann's example by using the same methodology to generate the noisy exemplar - randomly switching the elements of the exemplar with a probability of _P(switch) = .25_. \n",
    "\n",
    "Lets start with a single iteration of recall attempts for all the exemplars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.seed(123123)\n",
    "exemplars = LippmanExemplars.get_exemplars()[0:8]\n",
    "network = HopfieldNetwork(exemplars, learning_rule=\"Hebb\")\n",
    "\n",
    "print \"Number of neurons:{0}\".format(network.num_neurons)\n",
    "print \"Capacity: {0}\".format(network.capacity)\n",
    "\n",
    "for exemplar in exemplars:\n",
    "    noisy_exemplar = LippmanExemplars.add_noise(exemplar, p=.25)\n",
    "    results = network.asynchronous_recall(noisy_exemplar)\n",
    "\n",
    "    # output results of recall\n",
    "    figure, axes = plt.subplots(1, len(results) + 2, figsize=(30,30))\n",
    "    \n",
    "    # Original version\n",
    "    axes[0].imshow(LippmanExemplars.to_matrix(exemplar), cmap='Greys', interpolation='None')\n",
    "    axes[0].set_title(\"Exemplar\", fontdict={'fontsize':22})\n",
    "    axes[0]\n",
    "    \n",
    "    # Noisy version\n",
    "    axes[1].imshow(LippmanExemplars.to_matrix(noisy_exemplar), cmap='Greys', interpolation='None')\n",
    "    axes[1].set_title(\"Noisy Exemplar\", fontdict={'fontsize':22})\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        axes[i+2].imshow(LippmanExemplars.to_matrix(result), cmap='Greys', interpolation='None')\n",
    "        axes[i+2].set_title(\"Iteration {0} of recall\".format(i, fontdict={'fontsize':22}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results, the exemplars for 0, 3 and square block are successfully recovered.  However, the exemplars for 1, 2 and 4 return corrupted versions of the exemplar 3 because of considerable overlap in the digits.  The exemplar for 6 gravitates to 2.  The exemplar returned for 9 is clearly close, but not the original 9.\n",
    "\n",
    "The successful recovery of the training exemplar is in part dependent on the noise introduced in the noisy varient and the degree to which that noise might have shifted the noisy exemplar towards one of the other exemplars in the training set. We can therefore minimize the impact of variation in the noise by repeatedly running the experiment as a series of trials where the network is trained, a noisy varient of each exemplar generated and imposed on it, and the recalled exemplar evaluated to determine if it is the expected exemplar or not.  We'll run this trial 100 times and calculate and _error rate_ for the recovery of each exemplar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(123123)\n",
    "exemplars = LippmanExemplars.get_exemplars()[0:8]\n",
    "network = HopfieldNetwork(exemplars, learning_rule=\"Hebb\")\n",
    "\n",
    "\n",
    "error_rates = []\n",
    "for i, exemplar in enumerate(exemplars):\n",
    "    print \"Testing on exemplar {0}\".format(i)\n",
    "    errors = 0\n",
    "    for i in range(0, 100):\n",
    "        noisy_exemplar = LippmanExemplars.add_noise(exemplar, p=.25)\n",
    "        p = network.asynchronous_recall(noisy_exemplar)[-1]\n",
    "        if p != exemplar:\n",
    "            errors += 1\n",
    "    error_rates.append(1.0 * errors / 100)\n",
    "\n",
    "for i, rate in enumerate(error_rates):\n",
    "    print \"Error rate for exemplar: {0} was {1}%.\".format(i, rate * 100)\n",
    "    \n",
    "m = (1.0 * sum(error_rates)) / len(error_rates)\n",
    "print \"Mean error rate: {0}%\".format(m * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll repeat the experiment after training the Network using the Storkey Learning rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.seed(123123)\n",
    "exemplars = LippmanExemplars.get_exemplars()[0:8]\n",
    "network = HopfieldNetwork(exemplars, learning_rule=\"Storkey\")\n",
    "\n",
    "print \"Number of neurons:{0}\".format(network.num_neurons)\n",
    "print \"Capacity: {0}\".format(network.capacity)\n",
    "\n",
    "for exemplar in exemplars:\n",
    "    noisy_exemplar = LippmanExemplars.add_noise(exemplar, p=.25)\n",
    "    results = network.asynchronous_recall(noisy_exemplar)\n",
    "\n",
    "    # output results of recall\n",
    "    figure, axes = plt.subplots(1, len(results) + 2, figsize=(30,30))\n",
    "    \n",
    "    # Original version\n",
    "    axes[0].imshow(LippmanExemplars.to_matrix(exemplar), cmap='Greys', interpolation='None')\n",
    "    axes[0].set_title(\"Exemplar\", fontdict={'fontsize':22})\n",
    "    axes[0]\n",
    "    \n",
    "    # Noisy version\n",
    "    axes[1].imshow(LippmanExemplars.to_matrix(noisy_exemplar), cmap='Greys', interpolation='None')\n",
    "    axes[1].set_title(\"Noisy Exemplar\", fontdict={'fontsize':22})\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        axes[i+2].imshow(LippmanExemplars.to_matrix(result), cmap='Greys', interpolation='None')\n",
    "        axes[i+2].set_title(\"Iteration {0} of recall\".format(i, fontdict={'fontsize':22}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of our exemplars have improved recall.  We can see 0, 1, 4, 6, and the block exemplar are recovered successfully from the noisy varient. \n",
    "\n",
    "Lets followup by repeating our trials determine the error rates for each exemplar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(123123)\n",
    "exemplars = LippmanExemplars.get_exemplars()[0:8]\n",
    "network = HopfieldNetwork(exemplars, learning_rule=\"Storkey\")\n",
    "\n",
    "error_rates = []\n",
    "for i, exemplar in enumerate(exemplars):\n",
    "    print \"Testing on exemplar {0}\".format(i)\n",
    "    errors = 0\n",
    "    for i in range(0, 100):\n",
    "        noisy_exemplar = LippmanExemplars.add_noise(exemplar, p=.25)\n",
    "        p = network.asynchronous_recall(noisy_exemplar)[-1]\n",
    "        if p != exemplar:\n",
    "            errors += 1\n",
    "    error_rates.append(1.0 * errors / 100)\n",
    "\n",
    "for i, rate in enumerate(error_rates):\n",
    "    print \"Error rate for exemplar: {0} was {1}%.\".format(i, rate * 100)\n",
    "    \n",
    "m = (1.0 * sum(error_rates)) / len(error_rates)\n",
    "print \"Mean error rate: {0}%\".format(m * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've achieved a significant reduction in the mean error rate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###TODO:  Insert a side by side graph of the error rates per exemplar and discuss further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Experiment 2:  Saturating a Hopfield Network**\n",
    "\n",
    "The motivation for Storkey's new learning rule was to determine if the capacity limitations of a Hopfield Network could be improved upon while still retaining the desired learning rule characteristics of locality, incrementality and immediacy.  A Network trained via Hebbian learning will have the absolute capacity of $\\frac{n}{(2 \\ln{n})}$.  The Storkey Learning Rule can be show analytically to have the absolute capacity $\\frac{n}{(\\sqrt{2 \\ln{n}})}, which is a significant improvement.  Here we will exercise that by generating Hopfield Networks of increasing size (# of neurons) :\n",
    "\n",
    "n = 5\n",
    "- Hebbian\n",
    "- Storkey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5, 10):\n",
    "    hebbian = (1.0 * i) / (2 * math.log(i))\n",
    "    storkey = (1.0 * i) / math.sqrt(2 * math.log(i))\n",
    "    print \"For {0} nodes:  Hebb capactiy: {1},  Storkey capacity: {2}\".format(i, hebbian, storkey)\n",
    "    \n",
    "    p = i * .13\n",
    "    print \"P is {0}\".format(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####TODO:  insert description of the Storkey rule\n",
    "\n",
    "Now we'll train a new instance of a Hopfield Network using the _Storkey_ learning rule, with the same set of exemplars."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
